{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Mwc43Drgi01"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XXuS8fJIg-N0"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5NvNF-zshhzR"
   },
   "outputs": [],
   "source": [
    "path_to_file = 'shahnameh.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nTJONjaVhi6I"
   },
   "outputs": [],
   "source": [
    "text = open(path_to_file,'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dJEYIEmHhoX_"
   },
   "outputs": [],
   "source": [
    "text = text.replace(\"|\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "RE8FkgC8i5uY",
    "outputId": "f1c9d7d9-76ac-4549-e438-fa4457452e33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "به نام خداوند جان و خرد\n",
      "کزین برتر اندیشه برنگذرد\n",
      "خداوند نام و خداوند جای\n",
      "خداوند روزی ده رهنمای\n",
      "خداوند کیوان و گردان سپهر\n",
      "فروزنده ماه و ناهید و مهر\n",
      "ز نام و نشان و گمان برترست\n",
      "نگارندهٔ بر شده پیکرست\n",
      "به بینندگان آفریننده را\n",
      "نبینی مرنجان دو بیننده را\n",
      "نیابد بدو نیز اندیشه راه\n",
      "که او برتر از نام و از جایگاه\n",
      "سخن هر چه زین گوهران بگذرد\n",
      "نیابد بدو راه جان و خرد\n",
      "خرد گر سخن برگزیند همی\n",
      "همان را گزیند که بیند همی\n",
      "ستودن نداند کس او را چو هست\n",
      "میان بندگی را ببایدت بست\n",
      "خرد را و جان را همی سنجد اوی\n",
      "در اندیشهٔ سخته \n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data\n",
    " - removing unnecessary chars\n",
    " - encoding chars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UhUFeC-chpD7"
   },
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Yey-SUE-iAGR",
    "outputId": "ce68fe9f-3b7c-4ef2-c1e1-1d22c8e07254"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-fAhSPpNiBeW"
   },
   "outputs": [],
   "source": [
    "char_to_ind = {char:ind for ind,char in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k-lEr0Z0jLde"
   },
   "outputs": [],
   "source": [
    "ind_to_char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ydIvdsWbjODh"
   },
   "outputs": [],
   "source": [
    "encoded_text = np.array([char_to_ind[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CUe9279JlMpl"
   },
   "outputs": [],
   "source": [
    "seq_len = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_2PPPpMmlZKd"
   },
   "outputs": [],
   "source": [
    "total_num_seq = len(text) // (seq_len + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_IPhpDXXmQzZ",
    "outputId": "a7ca2e0e-a8ec-4d27-837d-08f8d35bed94"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102185"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_num_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8gy_rOHfmS_S"
   },
   "outputs": [],
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9uxu9CI_mevb"
   },
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(seq_len+1,drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oxoJP_S1mkLx"
   },
   "outputs": [],
   "source": [
    "def create_seq_target(seq):\n",
    "    input_text = seq[:-1]\n",
    "    target_text = seq[1:]\n",
    "    return input_text,target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lHxGJRfWmmkU"
   },
   "outputs": [],
   "source": [
    "dataset = sequences.map(create_seq_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "zR2ebOGxmoKj",
    "outputId": "f62deb4a-64f1-4aee-c921-3af20e4a1fb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14 37  1 36 13 35  1 19 20 13 38 36 20  1 17 13 36  1 38  1 19 22 20  0]\n",
      "به نام خداوند جان و خرد\n",
      "\n",
      "\n",
      "\n",
      "[37  1 36 13 35  1 19 20 13 38 36 20  1 17 13 36  1 38  1 19 22 20  0 43]\n",
      "ه نام خداوند جان و خرد\n",
      "ک\n"
     ]
    }
   ],
   "source": [
    "for input_text,target_text in dataset.take(1):\n",
    "    print(input_text.numpy())\n",
    "    print(\"\".join(ind_to_char[input_text.numpy()]))\n",
    "    print('\\n')\n",
    "    print(target_text.numpy())\n",
    "    print(\"\".join(ind_to_char[target_text.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MLXpAekmmqv0"
   },
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iRrAMu5emv-p"
   },
   "outputs": [],
   "source": [
    "buffer_size = 10000\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size,drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jjn5MkIumxc3"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h_315BnCmzHE"
   },
   "outputs": [],
   "source": [
    "embed_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WmdSyS6Um1Ns"
   },
   "outputs": [],
   "source": [
    "rnn_neurons = 1026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5mpKG6Ejm2r4"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U0bbNZ0Fm4Ue"
   },
   "outputs": [],
   "source": [
    "def sparse_cat_loss(y_true,y_pred):\n",
    "    return sparse_categorical_crossentropy(y_true,y_pred,from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KEEQb7xZm56B"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,GRU,Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ljYdgA7pm7QN"
   },
   "outputs": [],
   "source": [
    "# function to create model : we need to create model for forecasting with one sample\n",
    "def create_model(vocab_size,embed_dim,rnn_neurons,batch_size):\n",
    "    with tf.device('/gpu:0'):\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(vocab_size,embed_dim,batch_input_shape=[batch_size,None]))\n",
    "        model.add(GRU(rnn_neurons,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'))\n",
    "        model.add(Dense(vocab_size))\n",
    "        model.compile(optimizer='adam',loss=sparse_cat_loss)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6sGjN5Ssm-ua"
   },
   "outputs": [],
   "source": [
    "model = create_model(vocab_size,embed_dim,rnn_neurons,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "LhQG96PSnAP1",
    "outputId": "687b8786-52ae-4fa5-ece5-fd9fe7921fbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (128, None, 64)           3008      \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (128, None, 1026)         3361176   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (128, None, 47)           48269     \n",
      "=================================================================\n",
      "Total params: 3,412,453\n",
      "Trainable params: 3,412,453\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3gr_YbRsnCG_"
   },
   "outputs": [],
   "source": [
    "for input_example_batch,target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JVGwh2-wnEoJ"
   },
   "outputs": [],
   "source": [
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "XyfajGUMnKTO",
    "outputId": "240096d2-683b-4e45-afc4-3e599848a602"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "798/798 [==============================] - 45s 56ms/step - loss: 2.0902\n",
      "Epoch 2/30\n",
      "798/798 [==============================] - 45s 57ms/step - loss: 1.6494\n",
      "Epoch 3/30\n",
      "798/798 [==============================] - 45s 57ms/step - loss: 1.5566\n",
      "Epoch 4/30\n",
      "798/798 [==============================] - 46s 57ms/step - loss: 1.5085\n",
      "Epoch 5/30\n",
      "798/798 [==============================] - 46s 57ms/step - loss: 1.4761\n",
      "Epoch 6/30\n",
      "798/798 [==============================] - 46s 57ms/step - loss: 1.4502\n",
      "Epoch 7/30\n",
      "798/798 [==============================] - 46s 57ms/step - loss: 1.4299\n",
      "Epoch 8/30\n",
      "798/798 [==============================] - 46s 57ms/step - loss: 1.4125\n",
      "Epoch 9/30\n",
      "798/798 [==============================] - 45s 57ms/step - loss: 1.3980\n",
      "Epoch 10/30\n",
      "798/798 [==============================] - 46s 57ms/step - loss: 1.3853\n",
      "Epoch 11/30\n",
      "798/798 [==============================] - 46s 57ms/step - loss: 1.3746\n",
      "Epoch 12/30\n",
      "798/798 [==============================] - 46s 57ms/step - loss: 1.3652\n",
      "Epoch 13/30\n",
      "798/798 [==============================] - 45s 57ms/step - loss: 1.3576\n",
      "Epoch 14/30\n",
      "798/798 [==============================] - 46s 57ms/step - loss: 1.3509\n",
      "Epoch 15/30\n",
      "798/798 [==============================] - 46s 57ms/step - loss: 1.3452\n",
      "Epoch 16/30\n",
      "798/798 [==============================] - 46s 57ms/step - loss: 1.3407\n",
      "Epoch 17/30\n",
      "798/798 [==============================] - 45s 57ms/step - loss: 1.3371\n",
      "Epoch 18/30\n",
      "798/798 [==============================] - 46s 57ms/step - loss: 1.3335\n",
      "Epoch 19/30\n",
      "798/798 [==============================] - 45s 57ms/step - loss: 1.3317\n",
      "Epoch 20/30\n",
      "798/798 [==============================] - 46s 57ms/step - loss: 1.3300\n",
      "Epoch 21/30\n",
      "798/798 [==============================] - 46s 57ms/step - loss: 1.3287\n",
      "Epoch 22/30\n",
      "798/798 [==============================] - 46s 57ms/step - loss: 1.3285\n",
      "Epoch 23/30\n",
      "798/798 [==============================] - 45s 57ms/step - loss: 1.3278\n",
      "Epoch 24/30\n",
      "798/798 [==============================] - 46s 57ms/step - loss: 1.3278\n",
      "Epoch 25/30\n",
      "798/798 [==============================] - 46s 57ms/step - loss: 1.3276\n",
      "Epoch 26/30\n",
      "798/798 [==============================] - 46s 57ms/step - loss: 1.3289\n",
      "Epoch 27/30\n",
      "798/798 [==============================] - 46s 57ms/step - loss: 1.3297\n",
      "Epoch 28/30\n",
      "798/798 [==============================] - 46s 57ms/step - loss: 1.3314\n",
      "Epoch 29/30\n",
      "798/798 [==============================] - 46s 57ms/step - loss: 1.3328\n",
      "Epoch 30/30\n",
      "798/798 [==============================] - 45s 56ms/step - loss: 1.3351\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    model.fit(dataset,epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TX_Vgx6Ot6XK"
   },
   "outputs": [],
   "source": [
    "model.save('shahname.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating new model with the same weights with batchsize 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hp07QyghuAiv"
   },
   "outputs": [],
   "source": [
    "model = create_model(vocab_size,embed_dim,rnn_neurons,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BlbQOjTkuD-v"
   },
   "outputs": [],
   "source": [
    "model.load_weights('shahname.h5')\n",
    "model.build(input_shape=tf.TensorShape([1,None]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function for generating Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9P9s4sln-AR"
   },
   "outputs": [],
   "source": [
    "def generate_text(model,start_seed,gen_size=500,temp=1.0):\n",
    "\n",
    "    num_generate = gen_size\n",
    "    input_eval = [char_to_ind[s] for s in start_seed]\n",
    "    input_eval = tf.expand_dims(input_eval,0)\n",
    "    text_generated = []\n",
    "\n",
    "    temperature = temp\n",
    "\n",
    "    model.reset_states()\n",
    "\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions,0)\n",
    "\n",
    "        predictions = predictions / temperature\n",
    "\n",
    "        predicted_id = tf.random.categorical(predictions,num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        input_eval = tf.expand_dims([predicted_id],0)\n",
    "\n",
    "        text_generated.append(ind_to_char[predicted_id])\n",
    "\n",
    "    return (start_seed + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 672
    },
    "colab_type": "code",
    "id": "2SG8SW-RrELN",
    "outputId": "dba0f1cb-92b1-4715-94fd-41e6b83d8880"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ز گفتار تا عود و عود و عبیر\n",
      "چهارم که تابوت بد کش گنهک عاج\n",
      "همه خوب چهر\n",
      "کزین خاکشان فله‌های همی‌بگذرد\n",
      "دل هوا روشن ومارد به سر\n",
      "نکرد آن کشیدند صحرا اندرین\n",
      "همه پیش برهان هلاکه کرد\n",
      "زن کودکان مادر گفت کای رنج کار\n",
      "به گوش سپه را سرافراز تو راست منذر سخن\n",
      "یکی گرزهٔ رادرون کرد کشتی چوشید\n",
      "پیاده برفتی کند ار خسپر نامبردار گرد\n",
      "همی شد ز بهرام هنگه هزار\n",
      "بزرگست و شادیش کردند ما گنج تو\n",
      "ببرجشنگهایی همه پیش شاه ارد این سخن\n",
      "بدو گفت شاها که اسکندر آیی به باراز شما شست هرگز دروغ\n",
      "حل‌آوری سال نیک\n",
      "به پرورد تا هم‌زن\n",
      "همه خاک را خویش تست\n",
      "و را پوست او رونهزار\n",
      "به گیتیتری\n",
      "به از راه دیوار کیست\n",
      "به ز چشم بنه برنهاد\n",
      "بدر و فر یزدگرد\n",
      "چنان گفت پس چندی بخسرو نگردد به پیش\n",
      "چنان چون بود درخور مهربان تیرباران اوی\n",
      "نی ز تخت مهی را سزاست\n",
      "بگفت و به شیر ژیان برگذشت\n",
      "ز اکو پیش\n",
      "همه پر هر به پای نشاید نهفت\n",
      "مهان سوی خاک رویین فراز و نشیب\n",
      "وگرنه نیوشم نبود\n",
      "بدان تا رقعه و پاک بیزارمش\n",
      "ز ایرانیان برفرازد همی\n",
      "ن خرد\n",
      "ز دینار و بر ما گذشتی سخن\n",
      "تو رابا سر تاجدار سپاه\n",
      "چو آمد به دل دانش و را پای کنداوران\n",
      "همی بفت خواهم کنون نیست اندرکشتم آید نخست او زریر سوار\n",
      "چو شی کبده گفت اگر \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model,'ز گفتار تا عود و عود و عبیر',gen_size=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-qgoCFO2rN29"
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(model.history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XrSt_TwFtlZ-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Shahname.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
