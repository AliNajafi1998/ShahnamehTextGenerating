{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Shahname.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Mwc43Drgi01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXuS8fJIg-N0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NvNF-zshhzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_to_file = 'shahname.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTJONjaVhi6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = open(path_to_file,'r').read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJEYIEmHhoX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = text.replace(\"|\", \"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RE8FkgC8i5uY",
        "colab_type": "code",
        "outputId": "f1c9d7d9-76ac-4549-e438-fa4457452e33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "print(text[:500])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "به نام خداوند جان و خرد\n",
            "کزین برتر اندیشه برنگذرد\n",
            "خداوند نام و خداوند جای\n",
            "خداوند روزی ده رهنمای\n",
            "خداوند کیوان و گردان سپهر\n",
            "فروزنده ماه و ناهید و مهر\n",
            "ز نام و نشان و گمان برترست\n",
            "نگارندهٔ بر شده پیکرست\n",
            "به بینندگان آفریننده را\n",
            "نبینی مرنجان دو بیننده را\n",
            "نیابد بدو نیز اندیشه راه\n",
            "که او برتر از نام و از جایگاه\n",
            "سخن هر چه زین گوهران بگذرد\n",
            "نیابد بدو راه جان و خرد\n",
            "خرد گر سخن برگزیند همی\n",
            "همان را گزیند که بیند همی\n",
            "ستودن نداند کس او را چو هست\n",
            "میان بندگی را ببایدت بست\n",
            "خرد را و جان را همی سنجد اوی\n",
            "در اندیشهٔ سخته \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhUFeC-chpD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = sorted(set(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yey-SUE-iAGR",
        "colab_type": "code",
        "outputId": "ce68fe9f-3b7c-4ef2-c1e1-1d22c8e07254",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fAhSPpNiBeW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char_to_ind = {char:ind for ind,char in enumerate(vocab)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-lEr0Z0jLde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ind_to_char = np.array(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydIvdsWbjODh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_text = np.array([char_to_ind[c] for c in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUe9279JlMpl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_len = 24"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2PPPpMmlZKd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_num_seq = len(text) // (seq_len + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IPhpDXXmQzZ",
        "colab_type": "code",
        "outputId": "a7ca2e0e-a8ec-4d27-837d-08f8d35bed94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "total_num_seq"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "102185"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gy_rOHfmS_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uxu9CI_mevb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = char_dataset.batch(seq_len+1,drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxoJP_S1mkLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_seq_target(seq):\n",
        "    input_text = seq[:-1]\n",
        "    target_text = seq[1:]\n",
        "    return input_text,target_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHxGJRfWmmkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = sequences.map(create_seq_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR2ebOGxmoKj",
        "colab_type": "code",
        "outputId": "f62deb4a-64f1-4aee-c921-3af20e4a1fb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "for input_text,target_text in dataset.take(1):\n",
        "    print(input_text.numpy())\n",
        "    print(\"\".join(ind_to_char[input_text.numpy()]))\n",
        "    print('\\n')\n",
        "    print(target_text.numpy())\n",
        "    print(\"\".join(ind_to_char[target_text.numpy()]))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[14 37  1 36 13 35  1 19 20 13 38 36 20  1 17 13 36  1 38  1 19 22 20  0]\n",
            "به نام خداوند جان و خرد\n",
            "\n",
            "\n",
            "\n",
            "[37  1 36 13 35  1 19 20 13 38 36 20  1 17 13 36  1 38  1 19 22 20  0 43]\n",
            "ه نام خداوند جان و خرد\n",
            "ک\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLXpAekmmqv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRrAMu5emv-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "buffer_size = 10000\n",
        "dataset = dataset.shuffle(buffer_size).batch(batch_size,drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jjn5MkIumxc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_315BnCmzHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_dim = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmdSyS6Um1Ns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_neurons = 1026"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mpKG6Ejm2r4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.losses import sparse_categorical_crossentropy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0bbNZ0Fm4Ue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sparse_cat_loss(y_true,y_pred):\n",
        "    return sparse_categorical_crossentropy(y_true,y_pred,from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEEQb7xZm56B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,GRU,Embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljYdgA7pm7QN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(vocab_size,embed_dim,rnn_neurons,batch_size):\n",
        "  with tf.device('/gpu:0'):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size,embed_dim,batch_input_shape=[batch_size,None]))\n",
        "    model.add(GRU(rnn_neurons,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'))\n",
        "    model.add(Dense(vocab_size))\n",
        "    model.compile(optimizer='adam',loss=sparse_cat_loss)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sGjN5Ssm-ua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_model(vocab_size,embed_dim,rnn_neurons,batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhQG96PSnAP1",
        "colab_type": "code",
        "outputId": "687b8786-52ae-4fa5-ece5-fd9fe7921fbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (128, None, 64)           3008      \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (128, None, 1026)         3361176   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (128, None, 47)           48269     \n",
            "=================================================================\n",
            "Total params: 3,412,453\n",
            "Trainable params: 3,412,453\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gr_YbRsnCG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for input_example_batch,target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVGwh2-wnEoJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MSB662iibbk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e06a6b76-0860-43d6-81b8-bc75c805170d"
      },
      "source": [
        "!hostname"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b0cadabcd5da\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyfajGUMnKTO",
        "colab_type": "code",
        "outputId": "240096d2-683b-4e45-afc4-3e599848a602",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "with tf.device('/gpu:0'):\n",
        "  model.fit(dataset,epochs=epochs)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "798/798 [==============================] - 45s 56ms/step - loss: 2.0902\n",
            "Epoch 2/30\n",
            "798/798 [==============================] - 45s 57ms/step - loss: 1.6494\n",
            "Epoch 3/30\n",
            "798/798 [==============================] - 45s 57ms/step - loss: 1.5566\n",
            "Epoch 4/30\n",
            "798/798 [==============================] - 46s 57ms/step - loss: 1.5085\n",
            "Epoch 5/30\n",
            "798/798 [==============================] - 46s 57ms/step - loss: 1.4761\n",
            "Epoch 6/30\n",
            "798/798 [==============================] - 46s 57ms/step - loss: 1.4502\n",
            "Epoch 7/30\n",
            "798/798 [==============================] - 46s 57ms/step - loss: 1.4299\n",
            "Epoch 8/30\n",
            "798/798 [==============================] - 46s 57ms/step - loss: 1.4125\n",
            "Epoch 9/30\n",
            "798/798 [==============================] - 45s 57ms/step - loss: 1.3980\n",
            "Epoch 10/30\n",
            "798/798 [==============================] - 46s 57ms/step - loss: 1.3853\n",
            "Epoch 11/30\n",
            "798/798 [==============================] - 46s 57ms/step - loss: 1.3746\n",
            "Epoch 12/30\n",
            "798/798 [==============================] - 46s 57ms/step - loss: 1.3652\n",
            "Epoch 13/30\n",
            "798/798 [==============================] - 45s 57ms/step - loss: 1.3576\n",
            "Epoch 14/30\n",
            "798/798 [==============================] - 46s 57ms/step - loss: 1.3509\n",
            "Epoch 15/30\n",
            "798/798 [==============================] - 46s 57ms/step - loss: 1.3452\n",
            "Epoch 16/30\n",
            "798/798 [==============================] - 46s 57ms/step - loss: 1.3407\n",
            "Epoch 17/30\n",
            "798/798 [==============================] - 45s 57ms/step - loss: 1.3371\n",
            "Epoch 18/30\n",
            "798/798 [==============================] - 46s 57ms/step - loss: 1.3335\n",
            "Epoch 19/30\n",
            "798/798 [==============================] - 45s 57ms/step - loss: 1.3317\n",
            "Epoch 20/30\n",
            "798/798 [==============================] - 46s 57ms/step - loss: 1.3300\n",
            "Epoch 21/30\n",
            "798/798 [==============================] - 46s 57ms/step - loss: 1.3287\n",
            "Epoch 22/30\n",
            "798/798 [==============================] - 46s 57ms/step - loss: 1.3285\n",
            "Epoch 23/30\n",
            "798/798 [==============================] - 45s 57ms/step - loss: 1.3278\n",
            "Epoch 24/30\n",
            "798/798 [==============================] - 46s 57ms/step - loss: 1.3278\n",
            "Epoch 25/30\n",
            "798/798 [==============================] - 46s 57ms/step - loss: 1.3276\n",
            "Epoch 26/30\n",
            "798/798 [==============================] - 46s 57ms/step - loss: 1.3289\n",
            "Epoch 27/30\n",
            "798/798 [==============================] - 46s 57ms/step - loss: 1.3297\n",
            "Epoch 28/30\n",
            "798/798 [==============================] - 46s 57ms/step - loss: 1.3314\n",
            "Epoch 29/30\n",
            "798/798 [==============================] - 46s 57ms/step - loss: 1.3328\n",
            "Epoch 30/30\n",
            "798/798 [==============================] - 45s 56ms/step - loss: 1.3351\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX_Vgx6Ot6XK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('shahname.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp07QyghuAiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_model(vocab_size,embed_dim,rnn_neurons,batch_size=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlbQOjTkuD-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('shahname.h5')\n",
        "model.build(input_shape=tf.TensorShape([1,None]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWTYms0FuEI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSyyV_5QuEG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDkhI7d1uEEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9P9s4sln-AR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model,start_seed,gen_size=500,temp=1.0):\n",
        "\n",
        "  num_generate = gen_size\n",
        "  input_eval = [char_to_ind[s] for s in start_seed]\n",
        "  input_eval = tf.expand_dims(input_eval,0)\n",
        "  text_generated = []\n",
        "\n",
        "  temperature = temp\n",
        "\n",
        "  model.reset_states()\n",
        "\n",
        "  for i in range(num_generate):\n",
        "    predictions = model(input_eval)\n",
        "    predictions = tf.squeeze(predictions,0)\n",
        "\n",
        "    predictions = predictions / temperature\n",
        "\n",
        "    predicted_id = tf.random.categorical(predictions,num_samples=1)[-1,0].numpy()\n",
        "\n",
        "    input_eval = tf.expand_dims([predicted_id],0)\n",
        "    \n",
        "    text_generated.append(ind_to_char[predicted_id])\n",
        "\n",
        "  return (start_seed + ''.join(text_generated))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SG8SW-RrELN",
        "colab_type": "code",
        "outputId": "dba0f1cb-92b1-4715-94fd-41e6b83d8880",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        }
      },
      "source": [
        "print(generate_text(model,'ز گفتار تا عود و عود و عبیر',gen_size=1000))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ز گفتار تا عود و عود و عبیر\n",
            "چهارم که تابوت بد کش گنهک عاج\n",
            "همه خوب چهر\n",
            "کزین خاکشان فله‌های همی‌بگذرد\n",
            "دل هوا روشن ومارد به سر\n",
            "نکرد آن کشیدند صحرا اندرین\n",
            "همه پیش برهان هلاکه کرد\n",
            "زن کودکان مادر گفت کای رنج کار\n",
            "به گوش سپه را سرافراز تو راست منذر سخن\n",
            "یکی گرزهٔ رادرون کرد کشتی چوشید\n",
            "پیاده برفتی کند ار خسپر نامبردار گرد\n",
            "همی شد ز بهرام هنگه هزار\n",
            "بزرگست و شادیش کردند ما گنج تو\n",
            "ببرجشنگهایی همه پیش شاه ارد این سخن\n",
            "بدو گفت شاها که اسکندر آیی به باراز شما شست هرگز دروغ\n",
            "حل‌آوری سال نیک\n",
            "به پرورد تا هم‌زن\n",
            "همه خاک را خویش تست\n",
            "و را پوست او رونهزار\n",
            "به گیتیتری\n",
            "به از راه دیوار کیست\n",
            "به ز چشم بنه برنهاد\n",
            "بدر و فر یزدگرد\n",
            "چنان گفت پس چندی بخسرو نگردد به پیش\n",
            "چنان چون بود درخور مهربان تیرباران اوی\n",
            "نی ز تخت مهی را سزاست\n",
            "بگفت و به شیر ژیان برگذشت\n",
            "ز اکو پیش\n",
            "همه پر هر به پای نشاید نهفت\n",
            "مهان سوی خاک رویین فراز و نشیب\n",
            "وگرنه نیوشم نبود\n",
            "بدان تا رقعه و پاک بیزارمش\n",
            "ز ایرانیان برفرازد همی\n",
            "ن خرد\n",
            "ز دینار و بر ما گذشتی سخن\n",
            "تو رابا سر تاجدار سپاه\n",
            "چو آمد به دل دانش و را پای کنداوران\n",
            "همی بفت خواهم کنون نیست اندرکشتم آید نخست او زریر سوار\n",
            "چو شی کبده گفت اگر \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qgoCFO2rN29",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pd.DataFrame(model.history.history).plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrSt_TwFtlZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}